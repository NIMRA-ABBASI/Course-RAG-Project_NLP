Consistent Hashing: The Need and Basic Concept 
Consistent hashing is a crucial technique used in distributed systems to distribute large amounts 
of data (or requests, or cache entries) across many servers (nodes) in a way that minimizes 
disruption when the number of servers changes. Databases like Apache Cassandra and Amazon 
DynamoDB utilize consistent hashing for efficient data distribution and scalability. 
The Challenge of Data Distribution: 
Imagine you have a vast amount of data that is too large to be stored on a single machine. The 
natural solution is to distribute this data across multiple servers. The core challenge then 
becomes: how to effectively and consistently map each piece of data (or key) to a specific 
server? 
One Simple Approach: Modulo Hashing (and its problem): 
A basic approach to data distribution is to use a simple hashing function. 
• Process: You take a document ID (or any key), pass it through a hash function (e.g., MD5, 
SHA-1) to generate a numerical hash value. Then, you take this hash value and perform 
a modulo operation with the current number of servers (N). The result (hash(key) % N) 
determines which server (from 0 to N-1) should store the document. 
• Example: If a document ID "30" hashes to a value of 41, and there are 4 servers, then 41 % 
4 = 1. The document would be stored on server 1. 
• The Problem (Rehashing on Server Change): While this modulo hashing method works 
initially, it faces a significant problem when servers are added or removed from the system 
(which happens frequently in dynamic cloud environments). If a server goes down (e.g., 
server 3 out of 4 servers), the number of servers (N) changes (from 4 to 3). Now, the logic for 
distributing data (hash(key) % 3) is different. This means a large portion of the existing 
data needs to be remapped and redistributed across the remaining servers. For 
instance, a key that was previously mapped to server 1 (41 % 4 = 1) might now map to 
server 2 (41 % 3 = 2). 
• Inefficiency: This constant and extensive redistribution of data whenever the server pool 
changes is inefficient and problematic, causing significant data movement, increased 
load, and potential service disruption. 
The Solution: Consistent Hashing 
This is where consistent hashing comes in. The core idea behind consistent hashing is that the 
distribution of data should not directly depend on the exact number of active servers in such a 

disruptive way. Instead of a simple modulo N, consistent hashing typically uses a circular hash 
space (a ring). 
• Circular Structure: The range of values generated by the hash function is mapped onto 
this conceptual circle. 
• Server Placement: Each server is also assigned one or more positions on this circle based 
on hashing its ID or IP address. 
• Data Mapping: When you want to store a document (or key), its ID is hashed, and the 
resulting hash value is mapped onto the circle. The document is then typically stored on 
the first server encountered when moving in a clockwise direction from the document's 
location on the circle. 
 